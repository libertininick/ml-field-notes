# Contents

1. [**Stop Using 80/20 Blindly**](1-stop-using-80-20-blindly.md): That 80/20 train-validation split you're using? It's probably either wasting thousands of labeled samples or giving you metrics too noisy to trust—and the fix requires thinking in absolute sample counts, not percentages.
2. [**The Label Noise That Actually Kills Your Model**](2-label-noise.md): Perfect training labels are overrated; but perfect evaluation data is non-negotiable and systematic labeling bias can destroy your model. Here's a simple technique to root out these biases in under an hour.
3. [**Which Samples Should You Label Next?**](3-what-to-label-next.md): You're probably selecting the wrong samples to label—this two-step strategy shows you how to maximize model improvement per labeled example while avoiding catastrophic forgetting.

---

[Back to Series Overview](../README.md#series-overview)